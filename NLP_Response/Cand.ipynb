{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import spacy\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('Candidature.csv', encoding='utf-8')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Tokenization\n",
    "    return text\n",
    "\n",
    "for text in df['Contenu']:\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    df['Contenu'] = df['Contenu'].replace(text, preprocessed_text)\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def spacy_tokenizer(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return \" \".join([token.text for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "df[\"Contenu_Lemmatise\"] = df[\"Contenu\"].apply(spacy_tokenizer)\n",
    "\n",
    "X = df[\"Contenu_Lemmatise\"]\n",
    "y = df[\"Réponse\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test =X[8:], X[:8],y[8:], y[:8] \n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "text = [\"Merci pour votre candidature. Nous souhaiterions vous rencontrer pour un entretien afin d'échanger davantage sur votre profil. Merci de nous indiquer vos disponibilités cette semaine.\",\n",
    "  \"Après examen de votre candidature, nous avons le regret de vous informer que votre profil n’a pas été retenu pour ce poste.Nous vous remercions pour l'intérêt porté à notre entreprise.\",\n",
    "  \"Suite à nos échanges et votre entretien, nous sommes heureux de vous proposer le poste de Data Analyst Junior. Vous trouverez ci-joint les documents nécessaires à la suite du processus.Au plaisir de vous compter parmi nous\",\n",
    "\"Nous vous remercions pour votre candidature. Vous êtes convié(e) à un entretien technique le [date/heure], en visioconférence. Merci de confirmer votre présence.\",\n",
    "\"Nous avons bien reçu votre candidature. Après analyse, nous avons décidé de ne pas donner suite à votre profil pour ce poste.Nous vous souhaitons une bonne continuation.\",\n",
    "\"Nous vous remercions pour le temps consacré à nos échanges. Nous avons le plaisir de vous informer que vous êtes retenu(e) pour la prochaine étape du processus de recrutement.\",\n",
    "\"Malgré l’intérêt que présente votre profil, nous avons décidé de poursuivre avec d’autres candidatures. Nous vous remercions pour votre démarche et restons disponibles pour un retour.\",\n",
    "\"Nous avons le plaisir de vous annoncer que vous avez été sélectionné(e) pour rejoindre notre équipe en tant que Data Scientist Junior. Merci de bien vouloir confirmer votre acceptation avant le [date].\",\n",
    "\"Votre candidature a retenu notre attention. Nous souhaitons organiser un entretien RH afin d’échanger sur vos motivations et votre parcours. Merci de nous proposer vos disponibilités.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77904484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "text = [\"Merci pour votre candidature. Nous souhaiterions vous rencontrer pour un entretien afin d'échanger davantage sur votre profil. Merci de nous indiquer vos disponibilités cette semaine.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20526d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte : Merci pour votre candidature. Nous souhaiterions vous rencontrer pour un entretien afin d'échanger davantage sur votre profil. Merci de nous indiquer vos disponibilités cette semaine.\n",
      "➡️ Prédiction : En cours\n",
      "--------------------------------------------------------------------------------\n",
      "Temps d'exécution : 0.02 secondes\n"
     ]
    }
   ],
   "source": [
    "text = [\"Merci pour votre candidature. Nous souhaiterions vous rencontrer pour un entretien afin d'échanger davantage sur votre profil. Merci de nous indiquer vos disponibilités cette semaine.\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "start_time  = time.time()\n",
    "for t in text:\n",
    "    preprocessed = preprocess_text(t)\n",
    "    lemmatized = spacy_tokenizer(preprocessed)\n",
    "    vectorized = vectorizer.transform([lemmatized])\n",
    "    prediction = model.predict(vectorized)[0]\n",
    "    results.append((t, prediction))\n",
    "\n",
    "for original_text, prediction in results:\n",
    "    print(f\"Texte : {original_text}\\n➡️ Prédiction : {prediction}\\n{'-'*80}\")\n",
    "\n",
    "end_time  = time.time()\n",
    "\n",
    "print(f\"Temps d'exécution : {end_time - start_time:.2f} secondes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
